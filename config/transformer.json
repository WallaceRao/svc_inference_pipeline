{
    "base_config": "config/base.json",
    "model_type": "Transformer",
    "dataset": [
        "opencpop"
    ],
    "preprocess": {
        // acoustic features
        "extract_mel": true,
        "mel_min_max_norm": true,
        "extract_pitch": true,
        "pitch_extractor": "parselmouth",
        "extract_energy": true,
        // content features
        "extract_whisper_feature": true,
        "extract_content_vector_feature": false,
        "extract_wenet_feature": false,
        "extract_mert_feature": false,
        "extract_ppg_feature": false,
        // Default config for whisper 
        "whisper_model": "medium",
        "whisper_hop_size": 480, // 320 in 16k,  480 in 24k
        "whisper_batch_size": 30,
        // Default config for content vector 
        "hubert_file": "",
        // "hubert_file": "/mnt/workspace/zhangxueyao/SVC/Singing-Voice-Conversion-System/cuhkszsvc/extractor/content/hubert/checkpoint_best_legacy_500.pt",
        "content_vector_hop_size": 480, // 320 in 16k, 480 in 24k
        // Default config for mert 
        "mert_model": "m-a-p/MERT-v1-330M",
        "mert_feature_layer": -1,
        "mert_hop_size": 320, // 24k
        "ppg_model": "",
        // Default config 
        "n_mel": 100,
        "win_size": 1024, // todo
        "hop_size": 256,
        "sample_rate": 24000,
        "n_fft": 1024, // todo
        "fmin": 0,
        "fmax": 12000, // todo
        "f0_min": 65, // ~C2
        "f0_max": 800, //1100,    // ~C6(1100), ~G5(800)
        "pitch_bin": 256,
        "pitch_max": 1100.0,
        "pitch_min": 50.0,
        "is_label": true,
        "is_mu_law": true,
        "bits": 8,
        "mel_min_max_stats_dir": "mel_min_max_stats",
        "whisper_dir": "whisper",
        "content_vector_dir": "content_vector",
        "wenet_dir": "wenet",
        "mert_dir": "mert",
        "spk2id": "spk2id.json",
        "utt2spk": "utt2spk",
        // Features used for model training
        "use_mel": true,
        "use_min_max_norm_mel": true,
        "use_frame_pitch": true,
        "use_frame_energy": true,
        "use_log_scale_pitch": false,
        "use_log_scale_energy": false,
        "use_spkid": false,
        "use_whisper": true,
        "use_content_vector": false,
        "use_mert": false,
        "use_ppg": false,
    },
    "model": {
        "condition_encoder": {
            "merge_mode": "add",
            "input_melody_dim": 1,
            "use_log_f0": true,
            "n_bins_melody": 256, //# Quantization (0 for not quantization)
            "output_melody_dim": 384,
            "input_loudness_dim": 1,
            "use_log_loudness": true,
            "n_bins_loudness": 256,
            "output_loudness_dim": 384,
            // ****** Note by Xueyao: move these configs to exp_config.json (make the users know that)
            // "use_whisper": true,
            // "use_content_vector": false,
            // "use_mert": false,
            // "use_ppg": false,
            // "whisper_dim": 1024,
            // "content_vec_dim": 256,
            // "mert_dim": 256,
            // "ppg_dim": 256,
            "content_encoder_dim": 384,
            "output_singer_dim": 384,
            "singer_table_size": 512,
            "output_content_dim": 384,
        },
        "transformer":{
            "dropout": 0.1,
            "n_heads": 6,
            "n_layer": 6,
            "input_dim": 384,
            "output_dim": 100,
        }
    },
    "train": {
        "lronPlateau": {
        "factor": 0.9,
        "patience": 50,
        "min_lr": 2.0e-4,
        "verbose": true,
        },
        "adam": {
        "lr": 4.0e-4,
        },
    }
}